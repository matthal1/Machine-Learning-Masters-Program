{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1a01ebd",
   "metadata": {},
   "source": [
    "Binary Text Classification using Logistic Regression of ham and spam text messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb3708d",
   "metadata": {},
   "source": [
    "The workflow that this notebook will follow is as follows:\n",
    "\n",
    "1. Data Preprocessing: \n",
    "    -Load the dataset into sentences and labels\n",
    "    -Split the dataset into training, validation and testing sets \n",
    "    -Report the distribution in the form of a table\n",
    "    -Clean the data of any noise (urls, punctuation, and numbers) & change to lower case\n",
    "    -Tokenize input text into tokens, including work stemming and stopwords\n",
    "    -Build your own TD-IDF feature extractor using the training set\n",
    "2. Build a logistic regression classifier using using L2 regularization\n",
    "    -Derive the gradient of the objective function of LR with respect to w and b. \n",
    "    -Implement logistic regression via initialization, objective function, and gradient descent\n",
    "    -Implement accuracy, precision, recall and F1 score as test metrics\n",
    "    -Write a function for SGD and Mini-batch GD\n",
    "    -Evaluate the model of the test set and report the metrics \n",
    "3. Cross Validation\n",
    "    -Implement cross validation to choose the best hyperparameter lambda for the validation set\n",
    "4. Conclusion\n",
    "    -Analyze the results and compare to baseline\n",
    "5. Create a multiclass classifier from various authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4616ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d21b144",
   "metadata": {},
   "source": [
    "Load the dataset, include more information about what this importing section does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "751a07e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df = pd.read_csv('a1-data/SMSSpamCollection', sep='\\t', header=None, names=['label', 'text'])\n",
    "\n",
    "spam_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acbfba93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b79824c",
   "metadata": {},
   "source": [
    "Objective of the split_dataset function: \n",
    "    -Split the dataset ino training, validation and test sets\n",
    "    -Return each set split into features and labels (this enables easier tokenization later)\n",
    "    -This also allows for reproducubility as the split will not be exactly the same each time meaning the if the structure of the model is effecive it should learn at the same rate regardless of the data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49c3da8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df, train_size, val_size, test_size):\n",
    "    df = df.sample(frac=1,random_state=42).reset_index(drop=True)\n",
    "    n = len(df)\n",
    "    train_end = int(train_size *n)\n",
    "    val_end = train_end + int(val_size *n)\n",
    "\n",
    "    train_df = df.iloc[:train_end]\n",
    "    val_df = df.iloc[train_end:val_end]\n",
    "    test_df = df.iloc[val_end:n]\n",
    "\n",
    "    X_train, y_train = train_df[['text']], train_df['label']\n",
    "    X_val, y_val = val_df[['text']], val_df['label']\n",
    "    X_test, y_test = test_df[['text']], test_df[['label']]\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_dataset(spam_df, 0.6, 0.2, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7e2ab6",
   "metadata": {},
   "source": [
    "Output a table showing the number of samples in each class for the training, validation and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "098e7e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>2898</td>\n",
       "      <td>966</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>445</td>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(ham,)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(spam,)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Train  Validation  Test\n",
       "ham       2898         966     0\n",
       "spam       445         148     0\n",
       "(ham,)       0           0   961\n",
       "(spam,)      0           0   154"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def data_distribution(y_train, y_val, y_test):\n",
    "    df =pd.DataFrame({'Train': y_train.value_counts(), 'Validation': y_val.value_counts(), 'Test': y_test.value_counts()}).fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "data_distribution(y_train, y_val, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecbe3ca",
   "metadata": {},
   "source": [
    "Objective of the clean_data function:\n",
    "    -Remove punctuation, urls and numbers\n",
    "    -Change text to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "364f7ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>squeeeeeze this is christmas hug if u lik my f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and also ive sorta blown him off a couple time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mmm thats better now i got a roast down me id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mm have some kanji dont eat anything heavy ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>so theres a ring that comes with the guys cost...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  squeeeeeze this is christmas hug if u lik my f...\n",
       "1  and also ive sorta blown him off a couple time...\n",
       "2  mmm thats better now i got a roast down me id...\n",
       "3      mm have some kanji dont eat anything heavy ok\n",
       "4  so theres a ring that comes with the guys cost..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(X):\n",
    "    X = X.str.lower()\n",
    "    X = X.str.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    X = X.str.replace(\"http\\\\S+\", \"\", regex=True)\n",
    "    X = X.str.replace(\"https\\\\S+\", \"\", regex=True)\n",
    "    X = X.str.replace(\"\\\\d+\", \"\", regex=True)\n",
    "    return X\n",
    "\n",
    "X_train['text'] = clean_text(X_train['text'])\n",
    "X_val['text'] = clean_text(X_val['text'])\n",
    "X_test['text']= clean_text(X_test['text'])\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cb62c8",
   "metadata": {},
   "source": [
    "Tokenize the dataset:\n",
    "    -Remove whitespace between words\n",
    "    -Including word stems\n",
    "    -Removing stop words (removing common words that do not add any semantic value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401f3f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = {\n",
    "    \"a\", \"an\", \"the\", \"and\", \"or\", \"but\",\n",
    "    \"is\", \"are\", \"was\", \"were\", \"be\",\n",
    "    \"to\", \"of\", \"in\", \"on\", \"for\", \"with\",\n",
    "    \"that\", \"this\", \"it\", \"as\", \"at\"\n",
    "}\n",
    "\n",
    "def tokenize_text(X):\n",
    "    return X.split()\n",
    "\n",
    "def remove_stopwords(tokens, stopwords = STOPWORDS):\n",
    "    return [t for t in tokens if t not in stopwords]\n",
    "\n",
    "def step_tokens(tokens):\n",
    "    suffixes: [\"ing\", \"ly\", \"ed\", \"s\", \"es\", \"est\"]\n",
    "    for suf in suffixes:\n",
    "        if tokens.endswith(suf) and len(tokens) > len(suf) + 2:\n",
    "            return tokens[:-len(suf)]\n",
    "    return tokens\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
